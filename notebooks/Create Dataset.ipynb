{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b2e565",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/alyafey22/.cache/huggingface/datasets/arbml___parquet/MagedSaeed--ashaar-719bb58a76ea0092/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15d88f4d57942dd924ffc34af91f46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ashaar = load_dataset(\"arbml/ashaar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723d2e1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install gdown\n",
    "# !gdown https://drive.google.com/uc?id=18JcCCPwuvPVp4Tp3oeavjxzkJ056J_Fa\n",
    "# !unzip final_model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7755fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f6e9829f8b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import create_transformer_model, char2idx\n",
    "model = create_transformer_model()\n",
    "model.load_weights(\"content/drive/MyDrive/Research/Barmajan/Models/ashaar_model_vocab_changed_diacritized_fixed4_transformer_bs256_50k_with_prose_augment_balanced_dedup/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "170392a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels.txt', 'r') as f:\n",
    "    label2name = f.readlines()\n",
    "    label2name = [name.replace('\\n', '') for name in label2name]\n",
    "\n",
    "with open('labels_ar.txt', 'r') as f:\n",
    "    label2name_ar = f.readlines()\n",
    "    label2name_ar = [name.replace('\\n', '') for name in label2name_ar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a47545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "def predict_meter(bayt):\n",
    "    x = [[char2idx[char] for char in sent if char in char2idx] for sent in bayt]\n",
    "    x = pad_sequences(x, padding='post', value=0, maxlen = 128)\n",
    "    logits = model.predict(x)\n",
    "    \n",
    "    return Counter([label2name_ar[logit.argmax()]for logit in logits]).most_common(1)[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a61da2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_verse(sample):\n",
    "    chars = 'ابتثجحخدذرزسشصضطظعغفقكلمنهويىئءأؤة ى'\n",
    "    diacs = 'ْ~ًٌٍَُِّ'\n",
    "    map_chars = {'ک':'ك', 'ﺑ':'ب', 'ٹ':'ث', 'ی':'ى'}\n",
    "    out = []\n",
    "    for verse in sample['poem verses']:\n",
    "        proc_verse = ''\n",
    "        for char in verse:\n",
    "            if char in chars+diacs:\n",
    "                proc_verse += char\n",
    "            elif char in map_chars:\n",
    "                proc_verse += map_chars[char]\n",
    "        out.append(proc_verse)\n",
    "    sample ['poem verses'] = out\n",
    "    return sample\n",
    "\n",
    "def filter_poems(sample):\n",
    "    poem = sample['poem verses']\n",
    "    if len(poem) < 2:\n",
    "        return False\n",
    "    if len(poem) % 2 != 0:\n",
    "        return False\n",
    "    for verse in poem:\n",
    "        if len(verse) < 5:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0c14d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/alyafey22/.cache/huggingface/datasets/arbml___parquet/MagedSaeed--ashaar-719bb58a76ea0092/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-7fefbbdb344e7589.arrow\n"
     ]
    }
   ],
   "source": [
    "ashaar = ashaar.map(process_verse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a900a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/alyafey22/.cache/huggingface/datasets/arbml___parquet/MagedSaeed--ashaar-719bb58a76ea0092/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-29e1c1a88312add9.arrow\n"
     ]
    }
   ],
   "source": [
    "ashaar = ashaar.filter(filter_poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5828941c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['poem title', 'poem meter', 'poem verses', 'poem theme', 'poem url', 'poet name', 'poet description', 'poet url', 'poet era', 'poet location', 'poem description', 'poem language type'],\n",
       "        num_rows: 219946\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ashaar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83ef33bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['لَو كُنتَ أَطمَع بِالمَنام تَوهما',\n",
       " 'لَسالَت طَيفكَ أَن يَزور تَكَرما',\n",
       " 'حاشا صُدودك أَن تَذم فَِنَّها',\n",
       " 'تَحلو لَدَيَّ وَِن أُسيغَت عَلقَما',\n",
       " 'فَاِهجُر فَهَجرك لي التِفات مَودة',\n",
       " 'أَلقاهُ مِنكَ تَحنناً وَتَرَحُما',\n",
       " 'عَذب فُوادي بِالَّذي تَختارَهُ',\n",
       " 'لَو كُنتُ مَنسيّاً تَرَكتُ وَِنَّما',\n",
       " 'لَو لَم تَكُن بِغُبار طَرفِكَ كَحلت',\n",
       " 'عَين الغَزالة صَدّها وَجه الدُما',\n",
       " 'عَيدي لِفَقدِكَ مَأَتم لَو صافَحت',\n",
       " 'فيهِ المَسَرة خاطِري لَتَأَلَما',\n",
       " 'هاتَ ِسقِني كَأس المَلامة عاذِلي',\n",
       " 'وَأدر عَليَّ حَديثُهُ مُتَرَنِما',\n",
       " 'فَِذا ذَكرت ليَ الحَبيب يَكادُ مِن',\n",
       " 'طَربي يَقبل مَسمَعي مِنكَ الفَما',\n",
       " 'ِني لَأَعشَقُ في هَواهُ عَواذِلي',\n",
       " 'شَغَفاً بِهِ وَأَود فيهِ اللُوَّما',\n",
       " 'سَرق الرَسول بَلَحظِهِ مِن وَجهِهِ',\n",
       " 'حُسناً أَبى عَن ناظِري أَن يَكتما',\n",
       " 'دَعني أُسامر هَجرَهُ في خُلوة',\n",
       " 'فَكَفى لِمِثلي أَن يَراني مَحرَما',\n",
       " 'بَدرٌ مِن الأَتراك لَما أَن بَدا',\n",
       " 'تَرك البُدور تَرى لِعَينِكَ أَنجُما',\n",
       " 'تَسقي لَواحِظُهُ العُقول مُدامة',\n",
       " 'الصَحو مِنها لا يَزالُ محرّما',\n",
       " 'لَو بِتُ أَشكو ظُلمُهُ لَشَكَوتُهُ',\n",
       " 'لِمَليك هَذا الدَهر أَسما مَن سَما',\n",
       " 'مَلك مِن الِيمان جَرد صارِماً',\n",
       " 'بِالحَق حَتّى الكُفر أَصبَحَ مُسلِما',\n",
       " 'قَد جَهَز السُفن الَّتي صادَمَت',\n",
       " 'رَضوى بِأَيسر لَمحة لِتهدَّما',\n",
       " 'وَتُلهب البَحر الخِضَم مَهابَةً',\n",
       " 'مِنهُ فَظَنَتهُ كَريتُ جَهَنَما',\n",
       " 'لَو شاهَدَ المَطرود سَطوةَ باسِهِ',\n",
       " 'في صُلبِ دم لِلسُجود تَقَدَما',\n",
       " 'العَدل أَخرسَ كانَ قَبل زَمانِهِ',\n",
       " 'أَذنت لَهُ الأَيام أَن يَتَكَلَّما',\n",
       " 'يَذَر الدُجى بِالبَشر صُبحاً مُشرِقاً',\n",
       " 'وَالصُبح بِالِرهاب لَيلاً مُظلِما',\n",
       " 'لَم تَخط ساد الفَلافي عَهدِهِ',\n",
       " 'بَينَ الشَقائِقِ خيفة أَن تَتَهما',\n",
       " 'عقد النثار عَلى العِداة سَحائِباً',\n",
       " 'لَولا الحَيا لَسقى السَما مِنها دَما',\n",
       " 'وَدَعَت ظُباهُ الطَيرَ حَتّى أَنَّهُ',\n",
       " 'قَد يَكادُ يَسقُط فَرحة نسر السَما',\n",
       " 'لَو يَرتَضي حَمل السِهام لَغارة',\n",
       " 'لَرَأَيتُهُ اِتَخَذَ الكَواكب أَسهُما',\n",
       " 'أَو شاءَ أَن يَهب المُلوك لِبَعض ما',\n",
       " 'في رِقِهِ مُستَحقراً لَتَبَرما',\n",
       " 'صِحت مِن السقم العُقول بِحِلمِهِ',\n",
       " 'وَبِظِلِهِ الدين القَويم قَد اِحتَمى',\n",
       " 'تَب يا زَمان فَِن ذكرتك عِندَهُ',\n",
       " 'مِن قَبل أَن يَنهاكَ مُتَّ تَوَهُّما']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ashaar['train'][2]['poem verses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce9c7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_meters(sample):\n",
    "    meter = sample['poem meter']\n",
    "    verses = sample['poem verses'] \n",
    "    \n",
    "    if meter:\n",
    "        for label in label2name_ar:\n",
    "            if label in meter:\n",
    "                sample['poem meter'] = label\n",
    "        if meter == 'بسيط':\n",
    "            sample['poem meter'] = 'البسيط'\n",
    "        if 'خبب' in meter:\n",
    "            sample['poem meter'] = \"المتدارك\"\n",
    "        if meter in ['نثرية', 'شعر التفعيلة', 'شعر الحر', 'بحر التفعيلة', 'التفعيله']:\n",
    "            sample['poem meter'] = \"النثر\"\n",
    "    if meter in ['عمودية', 'العمودية', None]:\n",
    "        bayts = [verses[i] +' # '+ verses[i+1] for i in range(0, len(verses)-2, 2)]\n",
    "        if len(bayts):\n",
    "            sample['poem meter'] = predict_meter(bayts)\n",
    "\n",
    "    return sample\n",
    "\n",
    "filtered_meters = set()\n",
    "\n",
    "def filter_meters(sample):\n",
    "    meter = sample['poem meter']\n",
    "    for m in label2name_ar:\n",
    "        if m == meter:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "443cd042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 38). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1f7e2122-0fdb-41d1-a3b1-732865f4a741/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1f7e2122-0fdb-41d1-a3b1-732865f4a741/assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f6f1cd10c10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f6f14131520> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f6f140f9190> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f6f140f9a60> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f6f140fb310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f6f140fbcd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86968c237c449f99ae7e2019798567e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/219946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ashaar = ashaar.map(map_meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d59ed5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/219946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ashaar = ashaar.filter(filter_meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be7c41ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['poem title', 'poem meter', 'poem verses', 'poem theme', 'poem url', 'poet name', 'poet description', 'poet url', 'poet era', 'poet location', 'poem description', 'poem language type'],\n",
       "        num_rows: 212499\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ashaar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0f8a00b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'البسيط',\n",
       " 'الخفيف',\n",
       " 'الرجز',\n",
       " 'الرمل',\n",
       " 'السريع',\n",
       " 'الطويل',\n",
       " 'الكامل',\n",
       " 'المتدارك',\n",
       " 'المتقارب',\n",
       " 'المجتث',\n",
       " 'المديد',\n",
       " 'المضارع',\n",
       " 'المقتضب',\n",
       " 'المنسرح',\n",
       " 'النثر',\n",
       " 'الهزج',\n",
       " 'الوافر'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meters = set(ashaar['train']['poem meter'])\n",
    "meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b06f2ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'الخفيف': '<|meter_0|>', 'المضارع': '<|meter_1|>', 'المجتث': '<|meter_2|>', 'الرمل': '<|meter_3|>', 'البسيط': '<|meter_4|>', 'المتقارب': '<|meter_5|>', 'الوافر': '<|meter_6|>', 'المقتضب': '<|meter_7|>', 'المديد': '<|meter_8|>', 'النثر': '<|meter_9|>', 'الهزج': '<|meter_10|>', 'المتدارك': '<|meter_11|>', 'المنسرح': '<|meter_12|>', 'الطويل': '<|meter_13|>', 'الكامل': '<|meter_14|>', 'الرجز': '<|meter_15|>', 'السريع': '<|meter_16|>'}\n"
     ]
    }
   ],
   "source": [
    "meter_tokens = {meter:f'<|meter_{i}|>' for i, meter in enumerate(meters)}\n",
    "print(meter_tokens)\n",
    "with open(\"meter_tokens.json\", \"w\") as f:\n",
    "    json.dump(meter_tokens, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d02cf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None,\n",
       " 'قصيدة اعتذار',\n",
       " 'قصيدة الاناشيد',\n",
       " 'قصيدة المعلقات',\n",
       " 'قصيدة حزينه',\n",
       " 'قصيدة دينية',\n",
       " 'قصيدة ذم',\n",
       " 'قصيدة رثاء',\n",
       " 'قصيدة رومنسيه',\n",
       " 'قصيدة سياسية',\n",
       " 'قصيدة شوق',\n",
       " 'قصيدة عامه',\n",
       " 'قصيدة عتاب',\n",
       " 'قصيدة غزل',\n",
       " 'قصيدة فراق',\n",
       " 'قصيدة قصيره',\n",
       " 'قصيدة مدح',\n",
       " 'قصيدة هجاء',\n",
       " 'قصيدة وطنيه'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "themes = set(ashaar['train']['poem theme'])\n",
    "themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31e7df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "theme_tokens = {meter:f'<|theme_{i}|>' for i, meter in enumerate(themes)}\n",
    "with open(\"theme_tokens.json\", \"w\") as f:\n",
    "    json.dump(theme_tokens, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e627053",
   "metadata": {},
   "outputs": [],
   "source": [
    "ST_POEM_TOKEN = '<|psep|>'\n",
    "ED_POEM_TOKEN = '</|psep|>'\n",
    "VERSE_TOKEN = '<|vsep|>'\n",
    "ST_BAYT_TOKEN= '<|bsep|>'\n",
    "ED_BAYT_TOKEN= '</|bsep|>'\n",
    "PAD_TOKEN = '<|pad|>'\n",
    "EOT_TOKEN = '<|endoftext|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "910c9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bohour.qafiah import get_qafiyah\n",
    "import collections\n",
    "\n",
    "def get_qafiyah_majority(poem):\n",
    "    all_qafiyahs =[]\n",
    "    try:\n",
    "        for bayt in poem.split(ED_BAYT_TOKEN)[:-1]:\n",
    "            proc_bayt = bayt.replace(VERSE_TOKEN, '').replace(ST_BAYT_TOKEN, '').replace(ED_BAYT_TOKEN,'')\n",
    "            all_qafiyahs.append(get_qafiyah([proc_bayt])[0][0])\n",
    "        return collections.Counter(all_qafiyahs).most_common(1)[0][0]\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "def join_verses(sample):\n",
    "\n",
    "    verses = sample['poem verses']\n",
    "    meter = sample['poem meter']\n",
    "    theme = sample['poem theme']\n",
    "  \n",
    "    poem = ''.join([ f'{ST_BAYT_TOKEN} '+verses[i] +f' {VERSE_TOKEN} '+ verses[i+1]+ f' {ED_BAYT_TOKEN} ' for i in range(0, len(verses)-2, 2)])\n",
    "    qafiyah = get_qafiyah_majority(poem)\n",
    "    if meter is None:\n",
    "        raise\n",
    "    text = f\"{meter_tokens[meter]} {qafiyah} {theme_tokens[theme]} {ST_POEM_TOKEN} {poem.strip()} {ED_POEM_TOKEN}\"\n",
    "\n",
    "    return {'text':text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d353c023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/212499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ashaar = ashaar.map(join_verses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7e9b799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem title': 'من أي مولى ارتجي',\n",
       " 'poem meter': 'الرمل',\n",
       " 'poem verses': ['مِن أَي مَولى اِرتَجي',\n",
       "  'وَلاي باب التَجي',\n",
       "  'وَاللَهُ حَيٌّ رازِقٌ',\n",
       "  'يُعطي الجَزيل لمُرتَجي',\n",
       "  'رَب جَواد لَم يَزَل',\n",
       "  'مِن كُل ضيقٍ مَخرَجي',\n",
       "  'ِن رُحت أَرجوغَيرَهُ',\n",
       "  'خابَ الرواح مَع المَجي',\n",
       "  'يا عَيس مالي أَقصدي',\n",
       "  'باب الكَريم وَعَرجي',\n",
       "  'وَضَعي رِحالك وَاِرتَعي',\n",
       "  'فَالأُم حَمل المُزعجِ',\n",
       "  'وَتَوسَلي بِمُحمدٍ',\n",
       "  'وَبِلهِ كَي تَنتجي',\n",
       "  'الهاشمي المُصطَفى',\n",
       "  'صج الهُدى المُتَبَلِجِ',\n",
       "  'وَبِشَيبة الصَديق صا',\n",
       "  'حب كل فَضل أَبهَجِ',\n",
       "  'وَالسَيد الفاروق مِن',\n",
       "  'بِسِوى الهُدى لَم يَلهجِ',\n",
       "  'وَبصنوه عُثمان ذي الن',\n",
       "  'نورَين أَقوم مَنهَجِ',\n",
       "  'وَعَليٍّ الكرّار فا',\n",
       "  'تح كُل باب مُرتجِ',\n",
       "  'وَبَقية الصَحب الكِرا',\n",
       "  'م أَولي الثَنا المُتَأرجِ',\n",
       "  'هُم أَبحر الفَضل الَّذي',\n",
       "  'نَ بِغَيرِهُم لَم تُفرجِ',\n",
       "  'وَكَذا السَفينة ِن نَجَت',\n",
       "  'فَجَميع مَن فيها نَجي'],\n",
       " 'poem theme': 'قصيدة دينية',\n",
       " 'poem url': 'https://www.aldiwan.net/poem16183.html',\n",
       " 'poet name': 'الامير منجك باشا',\n",
       " 'poet description': 'منجك بن محمد بن منجك بن ابي بكر بن عبد القادر بن ابراهيم بن منجك اليوسفي الكبير\\nاكبر شعراء عصره من اهل دمشق من بيت امارة و رياسة\\nانفق في صباه ما ورثه عن ابوه و انزوى ثم رحل الى الديار التركية و مدح السلطان ابراهيم و لم يظفر بطائل\\nفعاد الى دمشق و عاش فيها في ستر و جاه الى ان توفي بها.',\n",
       " 'poet url': 'https://www.aldiwan.net/cat-poet-alamir-mnczyk-pasha',\n",
       " 'poet era': 'العصر العثماني',\n",
       " 'poet location': None,\n",
       " 'poem description': None,\n",
       " 'poem language type': None,\n",
       " 'text': '<|meter_3|> ج <|theme_18|> <|psep|> <|bsep|> مِن أَي مَولى اِرتَجي <|vsep|> وَلاي باب التَجي </|bsep|> <|bsep|> وَاللَهُ حَيٌّ رازِقٌ <|vsep|> يُعطي الجَزيل لمُرتَجي </|bsep|> <|bsep|> رَب جَواد لَم يَزَل <|vsep|> مِن كُل ضيقٍ مَخرَجي </|bsep|> <|bsep|> ِن رُحت أَرجوغَيرَهُ <|vsep|> خابَ الرواح مَع المَجي </|bsep|> <|bsep|> يا عَيس مالي أَقصدي <|vsep|> باب الكَريم وَعَرجي </|bsep|> <|bsep|> وَضَعي رِحالك وَاِرتَعي <|vsep|> فَالأُم حَمل المُزعجِ </|bsep|> <|bsep|> وَتَوسَلي بِمُحمدٍ <|vsep|> وَبِلهِ كَي تَنتجي </|bsep|> <|bsep|> الهاشمي المُصطَفى <|vsep|> صج الهُدى المُتَبَلِجِ </|bsep|> <|bsep|> وَبِشَيبة الصَديق صا <|vsep|> حب كل فَضل أَبهَجِ </|bsep|> <|bsep|> وَالسَيد الفاروق مِن <|vsep|> بِسِوى الهُدى لَم يَلهجِ </|bsep|> <|bsep|> وَبصنوه عُثمان ذي الن <|vsep|> نورَين أَقوم مَنهَجِ </|bsep|> <|bsep|> وَعَليٍّ الكرّار فا <|vsep|> تح كُل باب مُرتجِ </|bsep|> <|bsep|> وَبَقية الصَحب الكِرا <|vsep|> م أَولي الثَنا المُتَأرجِ </|bsep|> <|bsep|> هُم أَبحر الفَضل الَّذي <|vsep|> نَ بِغَيرِهُم لَم تُفرجِ </|bsep|> </|psep|>'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ashaar['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86edc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "def batch_iterator():\n",
    "    for i in range(0, len(ashaar['train']), batch_size):\n",
    "        yield ashaar['train'][i : i + batch_size][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cac1b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = \"\"\n",
    "for text in ashaar['train'][\"text\"]:\n",
    "    full_dataset += text\n",
    "char_cnt =len(set(list(full_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d69351a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "print(char_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3508d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'أ', 'ي', 'ؤ', 's', 'ٍ', 'َ', 'ق', '5', 'ذ', 'r', 'ْ', 'ِ', 'ص', 'ع', 'ء', 'ث', '6', '~', 'm', '>', '|', 'ف', '7', '2', 'ه', ' ', 'و', 'ا', 'ب', 'ن', '1', 'ك', 'ش', 'غ', 'ّ', 'h', '0', 'ر', 'ة', 'ظ', 'س', 'e', '9', 'ئ', 'ً', 'م', 'p', 'ض', 'ز', '<', 'ت', 'v', 'خ', 'ى', '4', '8', 't', 'b', 'ط', 'ٌ', '3', '/', 'ل', 'ُ', 'د', 'ج', 'ح', '_'}\n"
     ]
    }
   ],
   "source": [
    "print(set(list(full_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8044ebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|meter_0|>', '<|meter_1|>', '<|meter_2|>', '<|meter_3|>', '<|meter_4|>', '<|meter_5|>', '<|meter_6|>', '<|meter_7|>', '<|meter_8|>', '<|meter_9|>', '<|meter_10|>', '<|meter_11|>', '<|meter_12|>', '<|meter_13|>', '<|meter_14|>', '<|meter_15|>', '<|meter_16|>']\n"
     ]
    }
   ],
   "source": [
    "print(list(meter_tokens.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a806b083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|res_0|>', '<|res_1|>', '<|res_2|>', '<|res_3|>', '<|res_4|>', '<|res_5|>', '<|res_6|>', '<|res_7|>', '<|res_8|>', '<|res_9|>']\n"
     ]
    }
   ],
   "source": [
    "extra_tokens = [f'<|res_{i}|>' for i in range(10)]\n",
    "print(extra_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb76dfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "#This pre-tokenizer takes care of replacing all bytes of the given string with a corresponding representation, as well as splitting into words.\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.UnicodeScripts() #add space whether to add space at the first word\n",
    "special_tokens = [EOT_TOKEN, ST_POEM_TOKEN, ED_POEM_TOKEN, VERSE_TOKEN, ST_BAYT_TOKEN, ED_BAYT_TOKEN, PAD_TOKEN]+list(meter_tokens.values())+list(theme_tokens.values())+extra_tokens\n",
    "trainer = trainers.BpeTrainer(vocab_size=char_cnt+len(special_tokens), special_tokens=special_tokens)\n",
    "tokenizer.train_from_iterator(batch_iterator(), trainer=trainer)\n",
    "tokenizer.pad_token = PAD_TOKEN\n",
    "print(tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "147bebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast, AutoTokenizer\n",
    "gpt_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d7c8050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<|endoftext|>', '<|endoftext|>'), ('<|psep|>', '<|psep|>'), ('</|psep|>', '</|psep|>'), ('<|vsep|>', '<|vsep|>'), ('<|bsep|>', '<|bsep|>'), ('</|bsep|>', '</|bsep|>'), ('<|pad|>', '<|pad|>'), ('<|meter_0|>', '<|meter_0|>'), ('<|meter_1|>', '<|meter_1|>'), ('<|meter_2|>', '<|meter_2|>'), ('<|meter_3|>', '<|meter_3|>'), ('<|meter_4|>', '<|meter_4|>'), ('<|meter_5|>', '<|meter_5|>'), ('<|meter_6|>', '<|meter_6|>'), ('<|meter_7|>', '<|meter_7|>'), ('<|meter_8|>', '<|meter_8|>'), ('<|meter_9|>', '<|meter_9|>'), ('<|meter_10|>', '<|meter_10|>'), ('<|meter_11|>', '<|meter_11|>'), ('<|meter_12|>', '<|meter_12|>'), ('<|meter_13|>', '<|meter_13|>'), ('<|meter_14|>', '<|meter_14|>'), ('<|meter_15|>', '<|meter_15|>'), ('<|meter_16|>', '<|meter_16|>'), ('<|theme_0|>', '<|theme_0|>'), ('<|theme_1|>', '<|theme_1|>'), ('<|theme_2|>', '<|theme_2|>'), ('<|theme_3|>', '<|theme_3|>'), ('<|theme_4|>', '<|theme_4|>'), ('<|theme_5|>', '<|theme_5|>'), ('<|theme_6|>', '<|theme_6|>'), ('<|theme_7|>', '<|theme_7|>'), ('<|theme_8|>', '<|theme_8|>'), ('<|theme_9|>', '<|theme_9|>'), ('<|theme_10|>', '<|theme_10|>'), ('<|theme_11|>', '<|theme_11|>'), ('<|theme_12|>', '<|theme_12|>'), ('<|theme_13|>', '<|theme_13|>'), ('<|theme_14|>', '<|theme_14|>'), ('<|theme_15|>', '<|theme_15|>'), ('<|theme_16|>', '<|theme_16|>'), ('<|theme_17|>', '<|theme_17|>'), ('<|theme_18|>', '<|theme_18|>'), ('<|res_0|>', '<|res_0|>'), ('<|res_1|>', '<|res_1|>'), ('<|res_2|>', '<|res_2|>'), ('<|res_3|>', '<|res_3|>'), ('<|res_4|>', '<|res_4|>'), ('<|res_5|>', '<|res_5|>'), ('<|res_6|>', '<|res_6|>'), ('<|res_7|>', '<|res_7|>'), ('<|res_8|>', '<|res_8|>'), ('<|res_9|>', '<|res_9|>')]\n"
     ]
    }
   ],
   "source": [
    "print([(gpt_tokenizer.tokenize(sp)[0], sp) for sp in special_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f1e7078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpt_tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2cae1c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.dataset_dict:Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7a43f49c3744271811ac46f6c06acf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53eeab794fd74f4d9593fbe14313187a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/107 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45adec68723844ccba2ab76066c5a4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c125fb22c2aa45daa1db07b50666b84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/107 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcd55b83cac4db5bae6e80f10c0840f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ashaar.push_to_hub('ashaar_datasetv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4624d3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Zaid/ashaar_tokenizerv2/commit/5aa42fc45d97ddee91c44dcb21c07e6d01f46f6b', commit_message='Upload tokenizer', commit_description='', oid='5aa42fc45d97ddee91c44dcb21c07e6d01f46f6b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_tokenizer.push_to_hub('ashaar_tokenizerv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b07dfadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017ce033158f412b963ea1b84d4cdb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff91b772119c4efb871f02076d433f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b49c26e7c34f6c9456f0df3dec5b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/14.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482bd62e97ae4f23ab116e8aba4f6b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/12.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af83cbdac404af6840aa30b35e3a9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast, AutoTokenizer\n",
    "\n",
    "gpt_tokenizer = GPT2TokenizerFast.from_pretrained('Zaid/ashaar_tokenizerv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb5eb24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<|theme_0|>': 24, '<|theme_4|>': 28, ' ': 53, '<|res_3|>': 46, 'ش': 96, 'ة': 85, '<|meter_2|>': 9, '<|theme_11|>': 35, '5': 60, 'ٍ': 115, 'س': 95, 'ٌ': 114, '<|meter_8|>': 15, 'ِ': 118, 'ّ': 119, '<|theme_7|>': 31, 't': 75, '<|res_5|>': 48, '<|endoftext|>': 0, '<|theme_1|>': 25, 'ى': 111, '<|theme_2|>': 26, 'ق': 104, '<|meter_7|>': 14, '<|theme_14|>': 38, '<|res_2|>': 45, 'ت': 86, '|': 77, '<|theme_15|>': 39, 'ل': 106, '<|meter_0|>': 7, 'أ': 80, '<|meter_9|>': 16, '<|theme_17|>': 41, '<|meter_5|>': 12, '<|theme_10|>': 34, '<|theme_6|>': 30, '<|theme_12|>': 36, 'ؤ': 81, 'h': 70, 'ز': 94, 'ي': 112, '<|theme_16|>': 40, 'خ': 90, 'ن': 108, '</|bsep|>': 5, 'ط': 99, 'ف': 103, '<|theme_9|>': 33, '7': 62, 'ء': 79, 'm': 71, '<|vsep|>': 3, '<|pad|>': 6, 'ص': 97, 'ه': 109, '<|meter_4|>': 11, '<|bsep|>': 4, 'ئ': 82, '<|meter_14|>': 21, '/': 54, '3': 58, 'و': 110, '8': 63, '<|meter_1|>': 8, '<|meter_13|>': 20, 'r': 73, 'ا': 83, '<|res_4|>': 47, '<|meter_15|>': 22, '_': 67, 'ظ': 100, '<|meter_12|>': 19, '<': 65, '<|res_6|>': 49, '<|res_1|>': 44, '<|res_9|>': 52, 'b': 68, '<|theme_5|>': 29, 'ر': 93, 'p': 72, '0': 55, '2': 57, 'ُ': 117, '<|meter_6|>': 13, '<|meter_3|>': 10, '<|theme_13|>': 37, 'ع': 101, '<|theme_8|>': 32, 'ج': 88, '9': 64, 'ض': 98, 'غ': 102, 's': 74, 'م': 107, '1': 56, '4': 59, 'ث': 87, 'ك': 105, 'v': 76, 'َ': 116, 'ً': 113, '<|psep|>': 1, '<|theme_18|>': 42, 'ب': 84, 'ْ': 120, 'e': 69, '<|meter_16|>': 23, '<|res_8|>': 51, '~': 78, '<|theme_3|>': 27, '>': 66, '<|meter_10|>': 17, '<|res_0|>': 43, '<|res_7|>': 50, 'ذ': 92, 'د': 91, 'ح': 89, '</|psep|>': 2, '6': 61, '<|meter_11|>': 18}\n"
     ]
    }
   ],
   "source": [
    "print(gpt_tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0bb7228d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_tokenizer.encode('<|theme_0|>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
